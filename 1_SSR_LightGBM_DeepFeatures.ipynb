{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e3e0ca",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook focuses on extracting image features using three deep learning modelsâ€”two CNNs and one Transformer. The features generated by these networks are concatenated into a vector of 3,072 dimensions. Finally, the extracted features for the training and test datasets are stored in a CSV file.\n",
    "\n",
    "The dataset can be downloaded from the following link: https://jiangliu5.github.io/imqac.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba7507",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6892a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from models.iqa_module_proposed import model_map, FuseBackbones\n",
    "from utils.dataset_proposed import CustomDataset\n",
    "#from VCIP_IMQA.VCIP.IMQA.utils.convnext import convnext_tiny, convnext_small, convnext_base, convnext_large, convnext_xlarge, model_urls\n",
    "\n",
    "import warnings\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.autograd.graph\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"onnxscript.converter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6555499",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea443bb-470a-47e5-8f4d-341abf4e4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "NUM_WORKERS = 0 #os.cpu_count()\n",
    "AMOUNT_TO_GET = 1.0\n",
    "SEED = 42\n",
    "\n",
    "# Define target data directory\n",
    "BASELINE_NAME = f\"VCIP_IMQA/VCIP\"\n",
    "BASELINE = Path(BASELINE_NAME)\n",
    "TARGET_DIR = BASELINE / \"EQ420_image\"\n",
    "TARGET_LABEL = BASELINE / \"Labels\"\n",
    "TARGET_BASE = BASELINE / \"IMQA\"\n",
    "\n",
    "# Setup training and test directories\n",
    "TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "# Set seeds\n",
    "set_seeds(SEED)\n",
    "\n",
    "EXTRACT_FEATURES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279df5f",
   "metadata": {},
   "source": [
    "# Specifying Target Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01afed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate cuda benchmark\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "#if device == \"cuda\":\n",
    "#    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a1291e",
   "metadata": {},
   "source": [
    "# Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b811388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant definition\n",
    "IMG_SIZE = 512\n",
    "N_SPLITS = 8\n",
    "BATCH_SIZE = 1\n",
    "train_csv = pd.read_csv(TARGET_LABEL / 'mos_fold_train.csv') #.sample(frac=1)\n",
    "test_csv = pd.read_csv(TARGET_LABEL / 'mos_fold_test.csv') #.sample(frac=1)\n",
    "train_vector = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "test_vector = [9, 10]\n",
    "train_ids = train_csv[train_csv['folds'].isin(train_vector)]\n",
    "test_ids = test_csv[test_csv['folds'].isin(test_vector)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc364f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb09b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['swin_v2_s', 'efficientnet_b3', 'convnext_s']\n",
    "fuse_backbones = FuseBackbones(model_list=model_list, vector_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model temporarily\n",
    "temp_path = \"temp_model.pth\"\n",
    "torch.save(fuse_backbones.state_dict(), temp_path)\n",
    "\n",
    "# Get size in MB\n",
    "size_mb = os.path.getsize(temp_path) / (1024 * 1024)\n",
    "print(f\"Model size: {size_mb:.2f} MB\")\n",
    "\n",
    "# Clean up\n",
    "os.remove(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = r'H:\\outputs\\iqa_total_20250616_fold0mseadam.pth'\n",
    "#size_bytes = os.path.getsize(file_path)\n",
    "#size_mb = size_bytes / (1024 ** 2)\n",
    "\n",
    "#print(f\"File size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb77fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant definition\n",
    "IMG_SIZE = 512\n",
    "N_SPLITS = 8\n",
    "BATCH_SIZE = 1\n",
    "train_csv = pd.read_csv(TARGET_LABEL / 'mos_fold_train.csv') #.sample(frac=1)\n",
    "test_csv = pd.read_csv(TARGET_LABEL / 'mos_fold_test.csv') #.sample(frac=1)\n",
    "train_vector = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "test_vector = [9, 10]\n",
    "train_ids = train_csv[train_csv['folds'].isin(train_vector)]\n",
    "test_ids = test_csv[test_csv['folds'].isin(test_vector)]\n",
    "\n",
    "if EXTRACT_FEATURES:\n",
    "    # Pre-processing\n",
    "    manual_transforms = v2.Compose([\n",
    "        v2.Resize((IMG_SIZE), interpolation=InterpolationMode.BICUBIC),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Preparing dataloaders\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=CustomDataset(ids=train_ids, ref_dir=TARGET_DIR, transform=manual_transforms),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=CustomDataset(ids=test_ids, ref_dir=TARGET_DIR, transform=manual_transforms),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True)\n",
    "\n",
    "    # Create model\n",
    "    model_list = ['swin_v2_s', 'efficientnet_b3', 'convnext_s']\n",
    "    fuse_backbones = FuseBackbones(model_list=model_list, vector_size=None)\n",
    "    fuse_backbones.to(device)\n",
    "    fuse_backbones.eval()\n",
    "    fuse_backbones = fuse_backbones.float() \n",
    "\n",
    "    # Extract features - train dataset\n",
    "    train_features = []\n",
    "    train_mos = []\n",
    "    train_fold = []\n",
    "\n",
    "    for img, mos, fold, _, _ in tqdm(train_dataloader, desc=\"Extracting features (train)\"):\n",
    "        with torch.inference_mode():\n",
    "            features = fuse_backbones(img.to(device))\n",
    "        train_features.append(features.cpu())\n",
    "        train_mos.append(mos.cpu())\n",
    "        train_fold.append(fold.cpu())\n",
    "\n",
    "    # Tensor to numpy\n",
    "    train_features_np = torch.cat(train_features).numpy()\n",
    "    train_mos_np = torch.cat(train_mos).numpy()\n",
    "    train_fold_np = torch.cat(train_fold).numpy()\n",
    "\n",
    "    # Create column names\n",
    "    num_features = train_features_np.shape[1]\n",
    "    feature_columns = [f\"f_{i}\" for i in range(num_features)]\n",
    "    columns = feature_columns + ['fold'] + ['mos']\n",
    "\n",
    "    # Combine into DataFrame\n",
    "    train_df = pd.DataFrame(data=np.hstack([train_features_np, train_fold_np.reshape(-1, 1), train_mos_np.reshape(-1, 1)]), columns=columns)\n",
    "\n",
    "    # Extract features - test dataset\n",
    "    test_features = []\n",
    "    test_fold = []\n",
    "    test_names = []\n",
    "\n",
    "    for img, _, fold, name, _ in tqdm(test_dataloader, desc=\"Extracting features (test)\"):\n",
    "        with torch.inference_mode():\n",
    "            features = fuse_backbones(img.to(device))\n",
    "        test_features.append(features.cpu())\n",
    "        test_fold.append(fold.cpu())\n",
    "        test_names += list(name)\n",
    "        \n",
    "    # Tensor to numpy\n",
    "    test_features_np = torch.cat(test_features).numpy()\n",
    "    test_fold_np = torch.cat(test_fold).numpy()\n",
    "    test_names_np = np.array(test_names).reshape(-1, 1)\n",
    "\n",
    "    # Create column names\n",
    "    num_features = test_features_np.shape[1]\n",
    "    feature_columns = [f\"f_{i}\" for i in range(num_features)]\n",
    "    columns = ['image_name'] + feature_columns + ['fold']\n",
    "\n",
    "    # Combine into DataFrame    \n",
    "    test_df = pd.DataFrame(data=np.hstack([test_names_np, test_features_np, test_fold_np.reshape(-1, 1)]), columns=columns)\n",
    "\n",
    "    # (optional): Save\n",
    "    train_df.to_csv(\"train_features.csv\", index=False)\n",
    "    test_df.to_csv(\"test_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9db3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_features.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_features.csv')\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
