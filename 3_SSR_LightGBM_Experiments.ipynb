{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e3e0ca",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook evaluates the performance of the baseline and proposed IQA models. The assessment considers memory footprint, runtime, and quality metrics (PLCC, SROCC, and RMSE) at both the cross-validation and inference stages.\n",
    "\n",
    "The baseline model is described here: https://jiangliu5.github.io/imqac.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba7507",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6892a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import joblib\n",
    "import pickle\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from memory_profiler import memory_usage\n",
    "from models.iqa_module_baseline import mymodel\n",
    "from utils.dataset import MyDataset_xinbo\n",
    "from models.iqa_module_proposed import FuseBackbones, IQAModel\n",
    "from utils.dataset_proposed import CustomDataset\n",
    "\n",
    "import warnings\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.autograd.graph\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"onnxscript.converter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def seed_torch(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_torch(seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6555499",
   "metadata": {},
   "source": [
    "# Setting Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea443bb-470a-47e5-8f4d-341abf4e4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "NUM_WORKERS = 0\n",
    "AMOUNT_TO_GET = 1.0\n",
    "SEED = 42\n",
    "\n",
    "# Define target data directory\n",
    "BASELINE_NAME = f\"VCIP_IMQA/VCIP\"\n",
    "BASELINE = Path(BASELINE_NAME)\n",
    "TARGET_DIR = BASELINE / \"EQ420_image\"\n",
    "TARGET_LABEL = BASELINE / \"Labels\"\n",
    "TARGET_BASE = BASELINE / \"IMQA\"\n",
    "\n",
    "# Setup training and test directories\n",
    "TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create target model directory\n",
    "MODEL_DIR = Path(\"trained_3072to128\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_DIR2 = Path(\"trained_3072to128_weights\")\n",
    "MODEL_DIR2.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seeds(SEED)\n",
    "\n",
    "RUN_PROFILING_PROPOSED = True\n",
    "RUN_PROFILING_BASELINE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17cba38",
   "metadata": {},
   "source": [
    "# Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca_train(df, n_components):\n",
    "    pca = PCA(n_components=n_components, random_state=SEED)\n",
    "    X_pca = pca.fit_transform(df.drop(columns=['fold', 'mos']))\n",
    "    pca_columns = [f'PCA_{i}' for i in range(n_components)]\n",
    "    df_pca = pd.DataFrame(X_pca, columns=pca_columns, index=df.index)\n",
    "    df_pca['fold'] = df['fold']\n",
    "    df_pca['mos'] = df['mos']\n",
    "    return df_pca, pca\n",
    "\n",
    "def apply_pca_test(df, pca, n_components):    \n",
    "    X_pca = pca.transform(df.drop(columns=['image_name', 'fold']))\n",
    "    pca_columns = [f'PCA_{i}' for i in range(n_components)]\n",
    "    df_pca = pd.DataFrame(X_pca, columns=pca_columns, index=df.index)\n",
    "    df_pca['fold'] = df['fold']\n",
    "    df_pca['image_name'] = df['image_name']\n",
    "    return df_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73efb9",
   "metadata": {},
   "source": [
    "# Specifying Target Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01afed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate cuda benchmark\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80820a9",
   "metadata": {},
   "source": [
    "# Memory Profiling for the Proposed Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e39302",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_PROFILING_PROPOSED:\n",
    "\n",
    "    # Constant definition\n",
    "    IMG_SIZE = 512\n",
    "    BATCH_SIZE = 1\n",
    "    N_SPLITS = 8\n",
    "    PCA_COMPONENTS = 128\n",
    "    test_vector = [9, 10]\n",
    "    MODEL_ARCH =  MODEL_DIR / \"lgbm_model_fold\"\n",
    "    MODEL_ARCH2 =  MODEL_DIR2 / \"lgbm_model_fold\"\n",
    "    test_csv = pd.read_csv(TARGET_LABEL / 'mos_fold_test.csv') #.sample(frac=1)\n",
    "    test_ids = test_csv[test_csv['folds'].isin(test_vector)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4177ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_PROFILING_PROPOSED:\n",
    "    \n",
    "    # Save model temporarily\n",
    "    temp_path = \"temp_model.pth\"\n",
    "    model_list = ['swin_v2_s', 'efficientnet_b3', 'convnext_s']\n",
    "    fuse_backbones = FuseBackbones(model_list=model_list, vector_size=None)\n",
    "    torch.save(fuse_backbones.state_dict(), temp_path)\n",
    "\n",
    "    # Get size in MB\n",
    "    size_mb_bk = os.path.getsize(temp_path) / (1024 * 1024)\n",
    "    print(f\"Feature extractor: {size_mb_bk:.2f} MB\")\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(temp_path)\n",
    "\n",
    "    # Collect models in a list    \n",
    "    model_list = [\n",
    "            f'{MODEL_ARCH2}_mse_1_8_6.pkl',\n",
    "            f'{MODEL_ARCH}_mse_2_3_5.pkl',\n",
    "            f'{MODEL_ARCH2}_r2_3_8_4.pkl',\n",
    "            f'{MODEL_ARCH}_mse_4_3_6.pkl',\n",
    "            f'{MODEL_ARCH}_mse_5_1_5.pkl',     \n",
    "            f'{MODEL_ARCH2}_r2_6_4_5.pkl',\n",
    "            f'{MODEL_ARCH2}_r2_7_7_5.pkl',\n",
    "            f'{MODEL_ARCH2}_r2_8_6_6.pkl',\n",
    "    ]\n",
    "\n",
    "    size_mb_lgb = 0\n",
    "\n",
    "    for filename in model_list:\n",
    "        size_bytes = os.path.getsize(filename)\n",
    "        size_MB = size_bytes / (1024 ** 2)  # Convert to MB\n",
    "        size_mb_lgb += size_MB\n",
    "        print(f\"{filename}: {size_MB:.2f} MB\")\n",
    "\n",
    "    print(f\"\\nEnsemble: {size_mb_lgb:.2f} MB\")\n",
    "    print(f\"Total network size: {size_mb_bk + size_mb_lgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_PROFILING_PROPOSED:\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    def run_inference():\n",
    "\n",
    "        # Pre-processing\n",
    "        transforms = v2.Compose([\n",
    "            v2.Resize((IMG_SIZE), interpolation=InterpolationMode.BICUBIC),\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        test_dataloader = DataLoader(\n",
    "            dataset=CustomDataset(ids=test_ids, ref_dir=TARGET_DIR, transform=transforms),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True)\n",
    "\n",
    "        # Create model\n",
    "        fuse_backbones = FuseBackbones(model_list=['swin_v2_s', 'efficientnet_b3', 'convnext_s'], vector_size=None)\n",
    "        fuse_backbones.to(device)\n",
    "        fuse_backbones.eval()\n",
    "        fuse_backbones = fuse_backbones.float()\n",
    "\n",
    "        # Warm-up run (to load kernels, allocate caches, etc.)\n",
    "        with torch.inference_mode():\n",
    "            for img, _, _, _, _ in test_dataloader:        \n",
    "                _ = fuse_backbones(img.to(device))\n",
    "\n",
    "        peak      = torch.cuda.max_memory_allocated() / 1024**2\n",
    "        print(f\"[INFO] Warmup Max memory used: {peak:.2f} MB\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "        # Extract features\n",
    "        test_features = []\n",
    "        test_fold = []\n",
    "        test_names = []\n",
    "\n",
    "        print(f\"[INFO] Profiling started...\")\n",
    "\n",
    "        for img, _, fold, name, _ in test_dataloader:\n",
    "            with torch.inference_mode():\n",
    "                features = fuse_backbones(img.to(device))\n",
    "            test_features.append(features.cpu())\n",
    "            test_fold.append(fold.cpu())\n",
    "            test_names += list(name)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**2\n",
    "        reserved  = torch.cuda.memory_reserved() / 1024**2\n",
    "        peak      = torch.cuda.max_memory_allocated() / 1024**2\n",
    "\n",
    "        print(f\"[INFO] Current allocated: {allocated:.2f} MB\")\n",
    "        print(f\"[INFO] Memory reserved: {reserved:.2f} MB\")\n",
    "        print(f\"[INFO] Max memory used: {peak:.2f} MB\")\n",
    "            \n",
    "        # Tensor to numpy\n",
    "        test_features_np = torch.cat(test_features).numpy()\n",
    "        test_fold_np = torch.cat(test_fold).numpy()\n",
    "        test_names_np = np.array(test_names).reshape(-1, 1)\n",
    "\n",
    "        # Create column names\n",
    "        num_features = test_features_np.shape[1]\n",
    "        feature_columns = [f\"f_{i}\" for i in range(num_features)]\n",
    "        columns = ['image_name'] + feature_columns + ['fold']\n",
    "\n",
    "        # Combine into DataFrame\n",
    "        features_df = pd.DataFrame(data=np.hstack([test_names_np, test_features_np, test_fold_np.reshape(-1, 1)]), columns=columns)\n",
    "\n",
    "        # PCA for test set\n",
    "        # Fit PCA\n",
    "        train_df_orig = pd.read_csv('train_features.csv')\n",
    "        pca = PCA(n_components=PCA_COMPONENTS, random_state=SEED)\n",
    "        pca.fit(train_df_orig.drop(columns=['fold','mos']))\n",
    "\n",
    "        # Apply PCA on the test set\n",
    "        X_pca = pca.transform(features_df.drop(columns=['image_name', 'fold']))\n",
    "        pca_columns = [f'PCA_{i}' for i in range(PCA_COMPONENTS)]    \n",
    "        pca_df = pd.DataFrame(X_pca, columns=pca_columns, index=features_df.index)\n",
    "        pca_df['fold'] = features_df['fold'].astype(int)\n",
    "        pca_df['image_name'] = features_df['image_name']\n",
    "\n",
    "        # Collect models in a list\n",
    "        model_list = [\n",
    "                f'{MODEL_ARCH2}_mse_1_8_6.pkl',\n",
    "                f'{MODEL_ARCH}_mse_2_3_5.pkl',\n",
    "                f'{MODEL_ARCH2}_r2_3_8_4.pkl',\n",
    "                f'{MODEL_ARCH}_mse_4_3_6.pkl',\n",
    "                f'{MODEL_ARCH}_mse_5_1_5.pkl',     \n",
    "                f'{MODEL_ARCH2}_r2_6_4_5.pkl',\n",
    "                f'{MODEL_ARCH2}_r2_7_7_5.pkl',\n",
    "                f'{MODEL_ARCH2}_r2_8_6_6.pkl',\n",
    "        ]\n",
    "\n",
    "        models = []\n",
    "        for i in range(N_SPLITS):\n",
    "            model = joblib.load(model_list[i])\n",
    "            models.append(model)\n",
    "\n",
    "        pca_ids = pca_df[pca_df['fold'].isin(test_vector)]\n",
    "        X_test = pca_ids.drop(columns=['image_name', 'fold'])\n",
    "\n",
    "        preds_per_model = np.column_stack([model.predict(X_test) for model in models])\n",
    "        return preds_per_model.mean(axis=1)\n",
    "\n",
    "    mem_usage = memory_usage(run_inference)\n",
    "    print(f\"Max memory usage: {max(mem_usage):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a7a046",
   "metadata": {},
   "source": [
    "# Memory Profiling for the Baseline Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a52e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_PROFILING_BASELINE:\n",
    "    \n",
    "    file_path = r'H:\\outputs\\iqa_total_20250616_fold0mseadam.pth'\n",
    "    size_bytes = os.path.getsize(file_path)\n",
    "    size_mb = size_bytes / (1024 ** 2)\n",
    "\n",
    "    print(f\"Baseline network size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeccf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_PROFILING_BASELINE:\n",
    "    \n",
    "    TARGET_DIR = r'D:/Repos/ML_Projects/Image-Manipulation-Quality-Assessment/VCIP_IMQA/VCIP/EQ420_image/'\n",
    "    fold_vector = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    dfbase = pd.DataFrame(0, index=[f\"folder {i}\" for i in fold_vector] + [\"average\"] + [\"global\"], columns=['plcc base', 'srocc base', 'rmse base'])\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    all_pred_base = []\n",
    "    all_true_base = []\n",
    "    opt='adam'\n",
    "    error='mse'\n",
    "\n",
    "    def run_inference():\n",
    "        # Load models\n",
    "        models = []\n",
    "        for fold in range(1):\n",
    "            print(f\"Loading fold {fold + 1}...\")\n",
    "            model = mymodel()\n",
    "            model_name = f\"iqa_total_20250616_fold{fold}{error}{opt}.pth\"\n",
    "            model.load_state_dict(torch.load(model_name))\n",
    "            model = model.to(device)\n",
    "            model.eval()\n",
    "            models.append(model)\n",
    "            \n",
    "        fold_test = [9, 10]\n",
    "        test_csv = pd.read_csv(TARGET_LABEL / 'mos_fold_test.csv') #.sample(frac=1)\n",
    "        test_ids_base = test_csv[test_csv['folds'].isin(fold_test)]\n",
    "\n",
    "        # Prepare the dataloader\n",
    "        test_set = MyDataset_xinbo(ids=test_ids_base, ref_dir=TARGET_DIR)\n",
    "        test_dataloader = {'test':DataLoader(test_set, batch_size=1,shuffle=False, num_workers=4)}\n",
    "\n",
    "        # For each OOF image\n",
    "        cont = 0\n",
    "        for sample in test_dataloader[\"test\"]:\n",
    "            cont += 1\n",
    "            img = sample['ref']\n",
    "            img = img.to(device, dtype=torch.float)\n",
    "            with torch.set_grad_enabled(False):\n",
    "                test_preds = []\n",
    "                for model in models:\n",
    "                    score  = model(img).squeeze().cpu().item() \n",
    "                \n",
    "            if cont == 5:\n",
    "                break\n",
    "\n",
    "        peak      = torch.cuda.max_memory_allocated() / 1024**2\n",
    "        print(f\"[INFO] Warmup Max memory used: {peak:.2f} MB\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "        print(f\"[INFO] Profiling started...\")\n",
    "\n",
    "        # For each OOF image\n",
    "        mos_preds = []\n",
    "        for sample in test_dataloader[\"test\"]:\n",
    "            img = sample['ref']\n",
    "            img = img.to(device, dtype=torch.float)\n",
    "            with torch.set_grad_enabled(False):\n",
    "                test_preds = []\n",
    "                for model in models:\n",
    "                    score  = model(img).squeeze().cpu().item()       \n",
    "                    test_preds.append(score)\n",
    "                mos_preds.append(np.mean(test_preds))    \n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**2\n",
    "        reserved  = torch.cuda.memory_reserved() / 1024**2\n",
    "        peak      = torch.cuda.max_memory_allocated() / 1024**2\n",
    "\n",
    "        print(f\"[INFO] Current allocated: {allocated:.2f} MB\")\n",
    "        print(f\"[INFO] Memory reserved: {reserved:.2f} MB\")\n",
    "        print(f\"[INFO] Max memory used: {peak:.2f} MB\")\n",
    "\n",
    "        test_ids_base['mos'] = mos_preds\n",
    "        test_ids_base.drop(['folds'], axis=1, inplace=True) \n",
    "\n",
    "    mem_usage = memory_usage(run_inference)\n",
    "    print(f\"Max memory usage: {max(mem_usage):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a1291e",
   "metadata": {},
   "source": [
    "# Loading LightGBM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d913d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 1\n",
    "NUM_METRICS = 1\n",
    "N_SPLITS = 8\n",
    "idx_csv = pd.read_csv(TARGET_LABEL / 'mos_fold_train.csv') #.sample(frac=1)\n",
    "test_csv = pd.read_csv(TARGET_LABEL / 'mos_fold_test.csv') #.sample(frac=1)\n",
    "fold_vector = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "fold_test = [9, 10]\n",
    "MODEL_ARCH =  MODEL_DIR / \"lgbm_model_fold\"\n",
    "MODEL_ARCH2 =  MODEL_DIR2 / \"lgbm_model_fold\"\n",
    "train_df_orig = pd.read_csv('train_features.csv')\n",
    "test_df_orig = pd.read_csv('test_features.csv') #Suffix 2 includes a row with the names of the image files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68038d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 128\n",
    "train_df_s, pca_s = apply_pca_train(train_df_orig, N_COMPONENTS)\n",
    "test_df_s = apply_pca_test(test_df_orig, pca_s, N_COMPONENTS)\n",
    "\n",
    "# Define calibrator folder\n",
    "PCA_DIR = \"pca\"\n",
    "os.makedirs(PCA_DIR, exist_ok=True)  # Create if not exists\n",
    "\n",
    "# Save calibrator for this fold\n",
    "with open(f\"{PCA_DIR}/pca.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pca_s, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "manual_transforms = v2.Compose([\n",
    "    v2.Resize((IMG_SIZE), interpolation=InterpolationMode.BICUBIC),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Loading models\n",
    "model_list = [\n",
    "        (f'{MODEL_ARCH2}_mse_1_8_6.pkl', train_df_s, test_df_s),\n",
    "        (f'{MODEL_ARCH}_mse_2_3_5.pkl', train_df_s, test_df_s),\n",
    "        (f'{MODEL_ARCH2}_r2_3_8_4.pkl',  train_df_s, test_df_s),\n",
    "        (f'{MODEL_ARCH}_mse_4_3_6.pkl',  train_df_s, test_df_s),\n",
    "        (f'{MODEL_ARCH}_mse_5_1_5.pkl',   train_df_s, test_df_s),     \n",
    "        (f'{MODEL_ARCH2}_r2_6_4_5.pkl',   train_df_s, test_df_s),\n",
    "        (f'{MODEL_ARCH2}_r2_7_7_5.pkl',  train_df_s, test_df_s),\n",
    "        (f'{MODEL_ARCH2}_r2_8_6_6.pkl',  train_df_s, test_df_s),\n",
    "    ]\n",
    "\n",
    "APPLY_CALIBRATION_PER_FOLD = True\n",
    "\n",
    "lgb_models = []\n",
    "for i in range(N_SPLITS):\n",
    "    model = joblib.load(model_list[i][0])\n",
    "    lgb_models.append((model, model_list[i][1], model_list[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdebc640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = []\n",
    "\n",
    "for i, context in enumerate(lgb_models):\n",
    "    model = context[0]\n",
    "    params = model.get_params()\n",
    "    model_params.append({\n",
    "        \"Model\": f\"Model {i + 1}\",\n",
    "        \"n_estimators\": params.get(\"n_estimators\"),\n",
    "        \"learning_rate\": round(params.get(\"learning_rate\", 0), 3),\n",
    "        \"max_depth\": params.get(\"max_depth\"),\n",
    "        \"num_leaves\": params.get(\"num_leaves\"),\n",
    "        \"max_bin\": params.get(\"max_bin\", 255)  # Default to 255 if not available\n",
    "    })\n",
    "\n",
    "df_model_params = pd.DataFrame(model_params)\n",
    "\n",
    "print(\"TABLE II. \tBEST TRAINING SETUP PER CROSS-VALIDATION FOLD\")\n",
    "display(df_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64691566",
   "metadata": {},
   "source": [
    "# Computing Metrics for the Proposed Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2f08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store the results\n",
    "dfprop = pd.DataFrame(0, index=[f\"folder {i}\" for i in fold_vector] + [\"average\"] + [\"global\"], columns=['plcc prop', 'srocc prop', 'rmse prop'])\n",
    "\n",
    "fold_xyz = []\n",
    "all_pred_prop = []\n",
    "all_true_prop = []\n",
    "calibrators = []\n",
    "\n",
    "# Define calibrator folder\n",
    "CALIBRATOR_DIR = \"calibrators\"\n",
    "os.makedirs(CALIBRATOR_DIR, exist_ok=True)  # Create if not exists\n",
    "\n",
    "# Execute K-folds\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "for fold, (_, val_idx) in enumerate(kf.split(fold_vector)):\n",
    "\n",
    "    # Load data\n",
    "    model = lgb_models[fold][0]\n",
    "    train_df = lgb_models[fold][1]\n",
    "    # K-fold preparation\n",
    "    fold_val = fold_vector[val_idx[0]]\n",
    "    val_ids = train_df.loc[train_df['fold'] == fold_val]\n",
    "    X_val_fold = val_ids.drop(columns=['fold', 'mos'])\n",
    "    y_true = val_ids['mos'].values\n",
    "\n",
    "    # Predict using the model for this fold\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "\n",
    "    # Per-fold linear regression\n",
    "    lr_k = LinearRegression().fit(y_pred.reshape(-1, 1), y_true)\n",
    "    calibrators.append(lr_k)\n",
    "    \n",
    "    # Save calibrator for this fold\n",
    "    with open(f\"{CALIBRATOR_DIR}/calibrator_fold{fold}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(lr_k, f)\n",
    "\n",
    "    # Accumulate all predictions and ground truths\n",
    "    all_pred_prop.extend(y_pred)\n",
    "    all_true_prop.extend(y_true) \n",
    "\n",
    "    fold_xyz.append((y_pred, y_true))\n",
    "\n",
    "# Fit global regressor\n",
    "all_pred_np = np.array(all_pred_prop).reshape(-1, 1)\n",
    "all_true_np = np.array(all_true_prop).reshape(-1)\n",
    "\n",
    "# Compute calibrator\n",
    "lr = LinearRegression().fit(all_pred_np, all_true_np)\n",
    "\n",
    "all_pred_prop = []\n",
    "all_true_prop = []\n",
    "\n",
    "# Execute K-folds\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "for fold, (_, val_idx) in enumerate(kf.split(fold_vector)):\n",
    "\n",
    "    # Load data\n",
    "    model = lgb_models[fold][0]\n",
    "    train_df = lgb_models[fold][1]\n",
    "\n",
    "    # K-fold preparation\n",
    "    fold_val = fold_vector[val_idx[0]]\n",
    "    val_ids = train_df.loc[train_df['fold'] == fold_val]\n",
    "    X_val_fold = val_ids.drop(columns=['fold', 'mos'])\n",
    "    y_true = val_ids['mos'].values\n",
    "\n",
    "    # Predict using the model for this fold\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "\n",
    "    # Calibrate the estimated MOS\n",
    "    if APPLY_CALIBRATION_PER_FOLD:\n",
    "        y_pred = calibrators[fold].predict(y_pred.reshape(-1, 1))\n",
    "        #print(calibrators[fold].intercept_, calibrators[fold].coef_[0])\n",
    "    else:\n",
    "        y_pred = lr.predict(y_pred.reshape(-1, 1))\n",
    "        \n",
    "    # Accumulate all predictions and ground truths\n",
    "    all_pred_prop.extend(y_pred)\n",
    "    all_true_prop.extend(y_true)   \n",
    "\n",
    "    # Correlation metrics\n",
    "    plcc, _ = pearsonr(y_pred, y_true)    \n",
    "    srocc, _ = spearmanr(y_pred, y_true)    \n",
    "    rmse = root_mean_squared_error(y_pred, y_true) \n",
    "\n",
    "    # Store in dataframes\n",
    "    dfprop.iloc[fold] = [plcc, srocc, rmse]\n",
    "\n",
    "# Compute average metrics across folds and store in dataframes\n",
    "dfprop.loc['average'] = [dfprop['plcc prop'].iloc[:8].mean(), dfprop['srocc prop'].iloc[:8].mean(), dfprop['rmse prop'].iloc[:8].mean()]\n",
    "\n",
    "# Compute global metrics from all predictions and store in dataframes\n",
    "global_plcc_prop, _ = pearsonr(all_pred_prop, all_true_prop)\n",
    "global_srocc_prop, _ = spearmanr(all_pred_prop, all_true_prop)\n",
    "global_rmse_prop = root_mean_squared_error(all_pred_prop, all_true_prop)\n",
    "dfprop.loc['global'] = [global_plcc_prop, global_srocc_prop, global_rmse_prop]\n",
    "dfprop = dfprop.round(3)\n",
    "\n",
    "# Display dataframes\n",
    "print(\"Results for the proposed method\")\n",
    "display(dfprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eacaaf7",
   "metadata": {},
   "source": [
    "# Making Predictions on the Test Dataset Using the Proposed Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b80e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant definition\n",
    "N_SPLITS = 8\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 0\n",
    "BASELINE_NAME = f\"VCIP_IMQA/VCIP\"\n",
    "BASELINE = Path(BASELINE_NAME)\n",
    "TARGET_LABEL = BASELINE / \"Labels\"\n",
    "CALIBRATOR_DIR = \"calibrators\"\n",
    "PCA_DIR = 'pca'\n",
    "test_vector = [9, 10]\n",
    "MODEL_ARCH =  MODEL_DIR / \"lgbm_model_fold\"\n",
    "MODEL_ARCH2 =  MODEL_DIR2 / \"lgbm_model_fold\"\n",
    "test_csv = pd.read_csv(TARGET_LABEL / 'mos_fold_test.csv') #.sample(frac=1)\n",
    "test_ids = test_csv[test_csv['folds'].isin(test_vector)]\n",
    "\n",
    "# Load lgb models\n",
    "model_list = [\n",
    "        f'{MODEL_ARCH2}_mse_1_8_6.pkl',\n",
    "        f'{MODEL_ARCH}_mse_2_3_5.pkl',\n",
    "        f'{MODEL_ARCH2}_r2_3_8_4.pkl',\n",
    "        f'{MODEL_ARCH}_mse_4_3_6.pkl',\n",
    "        f'{MODEL_ARCH}_mse_5_1_5.pkl',     \n",
    "        f'{MODEL_ARCH2}_r2_6_4_5.pkl',\n",
    "        f'{MODEL_ARCH2}_r2_7_7_5.pkl',\n",
    "        f'{MODEL_ARCH2}_r2_8_6_6.pkl',\n",
    "    ]\n",
    "lgb_models = []\n",
    "for i in range(N_SPLITS):\n",
    "    model = joblib.load(model_list[i])\n",
    "    lgb_models.append(model)\n",
    "\n",
    "# Load calibrators\n",
    "calibrators = []\n",
    "for fold in range(N_SPLITS):\n",
    "    with open(f\"{CALIBRATOR_DIR}/calibrator_fold{fold}.pkl\", \"rb\") as f:\n",
    "        lr_k = pickle.load(f)\n",
    "    calibrators.append(lr_k)\n",
    "\n",
    "# Load PCA model\n",
    "with open(f\"{PCA_DIR}/pca.pkl\", \"rb\") as f:\n",
    "    pca_s = pickle.load(f)\n",
    "\n",
    "# Create test dataset\n",
    "manual_transforms = v2.Compose([\n",
    "    v2.Resize((IMG_SIZE), interpolation=InterpolationMode.BICUBIC),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = CustomDataset(\n",
    "    ids=test_ids,\n",
    "    ref_dir=TARGET_DIR,\n",
    "    transform=manual_transforms)\n",
    "\n",
    "# Instantate the IQA model\n",
    "iqa_model = IQAModel(\n",
    "    model_list=['swin_v2_s', 'efficientnet_b3', 'convnext_s'],    \n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    lgb_models=lgb_models,\n",
    "    calibrators=calibrators,\n",
    "    pca_model=pca_s,\n",
    "    dl_device=device,\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "df_preds = iqa_model.predict(test_dataset, len(test_dataset))\n",
    "\n",
    "# Display profiling\n",
    "results = iqa_model.profile().round(2)\n",
    "results[\"Device\"] = [\"CPU\", \"GPU\", \"CPU\", \"CPU\", \"CPU/GPU\", \"-\", \"-\"]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids_prop = test_csv.copy()\n",
    "test_ids_prop = test_ids_prop.drop(columns=['folds'])\n",
    "test_ids_prop['mos'] = test_ids_prop['image_name'].map(df_preds.set_index('image_name')['mos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5bce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print maximum and minimum MOS values\n",
    "print(f\"Max. prediction: {test_ids_prop['mos'].max()}\")\n",
    "print(f\"Min. prediction: {test_ids_prop['mos'].min()}\")\n",
    "\n",
    "# Store dataframe in the csv submission file\n",
    "#test_ids_prop.to_csv(f\"submitted_papers/Challenge Submission - Sergio-Sanz-Rodriguez_0717.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18116403",
   "metadata": {},
   "source": [
    "# Computing Metrics for the Baseline Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from models.iqa_module_baseline import mymodel\n",
    "from utils.dataset import MyDataset_xinbo\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba23c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_CSV_BASE = True\n",
    "\n",
    "# Load baseline results, its predictions have been previously made\n",
    "if READ_CSV_BASE:\n",
    "    #dfbase.to_csv(\"df_base.csv\",index=False)\n",
    "    #test_ids_base.to_csv(\"test_ids_base.csv\", index=False)\n",
    "    dfbase = pd.read_csv(\"df_base.csv\")\n",
    "    dfbase.index = [f\"folder {i+1}\" for i in range(8)] + [\"average\", \"global\"]\n",
    "    test_ids_base = pd.read_csv(\"test_ids_base.csv\")\n",
    "    with open(\"all_pred_base.pkl\", \"rb\") as f:\n",
    "        all_pred_base = pickle.load(f)\n",
    "\n",
    "    with open(\"all_true_base.pkl\", \"rb\") as f:\n",
    "        all_true_base = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    #TARGET_DIR = r'D:/Repos/ML_Projects/Image-Manipulation-Quality-Assessment/VCIP_IMQA/VCIP/EQ420_image/'\n",
    "    fold_vector = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    dfbase = pd.DataFrame(0, index=[f\"folder {i}\" for i in fold_vector] + [\"average\"] + [\"global\"], columns=['plcc base', 'srocc base', 'rmse base'])\n",
    "\n",
    "    all_pred_base = []\n",
    "    all_true_base = []\n",
    "    opt='adam'\n",
    "    error='mse'\n",
    "\n",
    "    # Load models\n",
    "    models = []\n",
    "    for fold in range(8):\n",
    "        print(f\"Loading fold {fold + 1}...\")\n",
    "        model = mymodel()\n",
    "        model_name = f\"H:/outputs/iqa_total_20250616_fold{fold}{error}{opt}.pth\"\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "\n",
    "    # Execute K-folds\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    for fold, (_, val_idx) in enumerate(kf.split(fold_vector)):\n",
    "\n",
    "        print(f\"Processing fold {fold + 1}...\")\n",
    "        \n",
    "        # K-fold preparation\n",
    "        fold_val = fold_vector[val_idx[0]]\n",
    "        val_ids = idx_csv.loc[idx_csv['folds'] == fold_val]\n",
    "        #y_true = val_ids['mos'].values\n",
    "\n",
    "        # Prepare the dataloader\n",
    "        val_set = MyDataset_xinbo(ids=val_ids, ref_dir=TARGET_DIR)\n",
    "        val_dataloader = {'val':DataLoader(val_set, batch_size=1,shuffle=False, num_workers=4)}\n",
    "        dataset_size = len(val_ids)\n",
    "\n",
    "        # Load model\n",
    "        model = models[fold]\n",
    "\n",
    "        # For each OOF image\n",
    "        y_pred = []\n",
    "        for sample_batched in val_dataloader[\"val\"]:\n",
    "            ref, mos = sample_batched['ref'], sample_batched['mos']\n",
    "            ref, mos = ref.type(torch.cuda.FloatTensor), mos.type(torch.cuda.FloatTensor)\n",
    "            ref, mos = ref.to(device), mos.to(device)\n",
    "            with torch.set_grad_enabled(False):\n",
    "                pred_score  = model(ref)\n",
    "                pred_score = pred_score.squeeze().cpu().item()\n",
    "                y_pred.append(pred_score)\n",
    "        \n",
    "        y_pred = np.array(y_pred).reshape(-1)\n",
    "        y_true = np.array(val_ids[\"mos\"].tolist()).reshape(-1)\n",
    "\n",
    "        # Accumulate all predictions and ground truths\n",
    "        all_pred_base.extend(y_pred)\n",
    "        all_true_base.extend(y_true)    \n",
    "\n",
    "        # Correlation metrics\n",
    "        plcc, _ = pearsonr(y_pred, y_true)    \n",
    "        srocc, _ = spearmanr(y_pred, y_true)    \n",
    "        rmse = root_mean_squared_error(y_pred, y_true)    \n",
    "\n",
    "        # Store in dataframes\n",
    "        dfbase.iloc[fold] = [plcc, srocc, rmse]\n",
    "        \n",
    "    # Compute average metrics across folds and store in dataframes\n",
    "    dfbase.loc['average'] = [dfbase['plcc base'].iloc[:8].mean(), dfbase['srocc base'].iloc[:8].mean(), dfbase['rmse base'].iloc[:8].mean()]\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # Compute global metrics from all predictions and store in dataframes\n",
    "    global_plcc_base, _ = pearsonr(all_pred_base, all_true_base)\n",
    "    global_srocc_base, _ = spearmanr(all_pred_base, all_true_base)\n",
    "    global_rmse_base = root_mean_squared_error(all_pred_base, all_true_base)\n",
    "    dfbase.loc['global'] = [global_plcc_base, global_srocc_base, global_rmse_base]\n",
    "    dfbase = dfbase.round(3)\n",
    "\n",
    "    # Display dataframes\n",
    "    print(\"Results for the baseline method\")\n",
    "    display(dfbase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb049424",
   "metadata": {},
   "source": [
    "# Making Predictions on the Test Dataset Using the Baseline Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not READ_CSV_BASE:\n",
    "    fold_test = [9, 10]\n",
    "    test_csv = pd.read_csv(TARGET_LABEL / 'mos_fold_test.csv') #.sample(frac=1)\n",
    "    test_ids_base = test_csv[test_csv['folds'].isin(fold_test)]\n",
    "\n",
    "    # Prepare the dataloader\n",
    "    test_set = MyDataset_xinbo(ids=test_ids_base, ref_dir=TARGET_DIR)\n",
    "    test_dataloader = {'test':DataLoader(test_set, batch_size=1,shuffle=False, num_workers=4)}\n",
    "\n",
    "    # For each OOF image\n",
    "    mos_preds = []\n",
    "    for sample in test_dataloader[\"test\"]:\n",
    "        img = sample['ref']\n",
    "        img = img.to(device, dtype=torch.float)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            test_preds = []\n",
    "            for model in models:\n",
    "                score  = model(img).squeeze().cpu().item()       \n",
    "                test_preds.append(score)\n",
    "            mos_preds.append(np.mean(test_preds))\n",
    "\n",
    "    test_ids_base['mos'] = mos_preds\n",
    "    test_ids_base.drop(['folds'], axis=1, inplace=True)   \n",
    "\n",
    "    print(f\"Max. prediction: {test_ids_base['mos'].max()}\")\n",
    "    print(f\"Min. prediction: {test_ids_base['mos'].min()}\")\n",
    "\n",
    "    del models, model, sample\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b967e",
   "metadata": {},
   "source": [
    "# Assessment Tables and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e799a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dfbase, dfprop], axis=1)\n",
    "df = df.round(3)\n",
    "\n",
    "print(\"TABLE III. COMPARISON OF BASELINE AND PROPOSED METHODS ACROSS FOLDS USING PLCC, SROCC, AND RMSE METRICS\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7050edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute calibrator\n",
    "lrb = LinearRegression().fit(np.array(all_pred_base).reshape(-1, 1), all_true_np)\n",
    "ab, bb = lrb.intercept_, lrb.coef_[0]\n",
    "lrp = LinearRegression().fit(np.array(all_pred_prop).reshape(-1, 1), all_true_prop)\n",
    "ap, bp = lrp.intercept_, lrp.coef_[0]\n",
    "print(ap, bp)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6.5, 3.5)) #, sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "axes[0].scatter(all_pred_base, all_true_base, alpha=0.5, color='grey')\n",
    "axes[0].plot(np.linspace(0, 1, 100), bb * np.linspace(0, 1, 100) + ab,\n",
    "                color='black', linestyle='dashed', linewidth=1)\n",
    "axes[1].scatter(all_pred_prop, all_true_prop, alpha=0.5, color='coral')\n",
    "axes[1].plot(np.linspace(0, 1, 100), bp * np.linspace(0, 1, 100) + ap,\n",
    "                color='black', linestyle='dashed', linewidth=1)\n",
    "axes[0].set_title(\n",
    "    f\"Baseline\\nPLCC = {df.loc['global','plcc base']}, SROCC = {df.loc['global','srocc base']}\"\n",
    ")\n",
    "axes[1].set_title(\n",
    "    f\"Proposal\\nPLCC = {df.loc['global','plcc prop']}, SROCC = {df.loc['global','srocc prop']}\"\n",
    ")\n",
    "axes[0].set_xlabel('Predicted MOS')\n",
    "axes[0].set_ylabel('True MOS')\n",
    "axes[1].set_xlabel('Predicted MOS')\n",
    "axes[1].set_ylabel('True MOS')\n",
    "axes[0].set_xlim(0, 1)\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[0].grid(True)\n",
    "axes[1].grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(r\"paper2/correlation_coral2_july17.tiff\", dpi=300, bbox_inches='tight')\n",
    "print(\"Figure 4. Correlation between predicted and true MOS on the OOF sets for the baseline (left) and proposed (right) models\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
